
Step:   0 Loss (unaveraged): 0.7316
Step:  10 Loss (unaveraged): 0.7276
Step:  20 Loss (unaveraged): 0.7245
Step:  30 Loss (unaveraged): 0.7323
Step:  40 Loss (unaveraged): 0.7240
Step:  50 Loss (unaveraged): 0.7140
Step:  60 Loss (unaveraged): 0.7090
Step:  70 Loss (unaveraged): 0.7010
Step:  80 Loss (unaveraged): 0.6970
Step:  90 Loss (unaveraged): 0.6902
Step: 100 Loss (unaveraged): 0.6794
Step: 110 Loss (unaveraged): 0.6837
Step: 120 Loss (unaveraged): 0.6612
Step: 130 Loss (unaveraged): 0.6599
Step: 140 Loss (unaveraged): 0.6429
Step: 150 Loss (unaveraged): 0.6409
Step: 160 Loss (unaveraged): 0.6174
Step: 170 Loss (unaveraged): 0.6164
Step: 180 Loss (unaveraged): 0.6096
Step: 190 Loss (unaveraged): 0.5985
Step: 200 Loss (unaveraged): 0.5820
Step: 210 Loss (unaveraged): 0.5637
Step: 220 Loss (unaveraged): 0.5473
Step: 230 Loss (unaveraged): 0.5333
Step: 240 Loss (unaveraged): 0.5168
Step: 250 Loss (unaveraged): 0.5034
Step: 260 Loss (unaveraged): 0.4879
Step: 270 Loss (unaveraged): 0.4709
Step: 280 Loss (unaveraged): 0.4511
Step: 290 Loss (unaveraged): 0.4348
Step: 300 Loss (unaveraged): 0.4115
Step: 310 Loss (unaveraged): 0.3961
Step: 320 Loss (unaveraged): 0.3798
Step: 330 Loss (unaveraged): 0.3489
Step: 340 Loss (unaveraged): 0.3285
Step: 350 Loss (unaveraged): 0.3135
Step: 360 Loss (unaveraged): 0.2850
Step: 370 Loss (unaveraged): 0.2606
Step: 380 Loss (unaveraged): 0.2398
Step: 390 Loss (unaveraged): 0.2098
Step: 400 Loss (unaveraged): 0.1919
Step: 410 Loss (unaveraged): 0.1605
Step: 420 Loss (unaveraged): 0.1356
Step: 430 Loss (unaveraged): 0.1067
Step: 440 Loss (unaveraged): 0.0804
Step: 450 Loss (unaveraged): 0.0530
Step: 460 Loss (unaveraged): 0.0216
Step: 470 Loss (unaveraged): -0.0061
Step: 480 Loss (unaveraged): -0.0400
Step: 490 Loss (unaveraged): -0.0691
Step: 500 Loss (unaveraged): -0.1056
Step: 510 Loss (unaveraged): -0.1293
Step: 520 Loss (unaveraged): -0.1612
Step: 530 Loss (unaveraged): -0.1902
Step: 540 Loss (unaveraged): -0.2259
Step: 550 Loss (unaveraged): -0.2568
Step: 560 Loss (unaveraged): -0.2804
Step: 570 Loss (unaveraged): -0.3025
Step: 580 Loss (unaveraged): -0.3380
Step: 590 Loss (unaveraged): -0.3627
Step: 600 Loss (unaveraged): -0.4014
Step: 610 Loss (unaveraged): -0.4103
Step: 620 Loss (unaveraged): -0.4191
Step: 630 Loss (unaveraged): -0.4427
Step: 640 Loss (unaveraged): -0.4711
Step: 650 Loss (unaveraged): -0.4612
Step: 660 Loss (unaveraged): -0.4813
Step: 670 Loss (unaveraged): -0.5121
Step: 680 Loss (unaveraged): -0.5004
Step: 690 Loss (unaveraged): -0.4891
Step: 700 Loss (unaveraged): -0.4976
Step: 710 Loss (unaveraged): -0.4893
Step: 720 Loss (unaveraged): -0.4823
Step: 730 Loss (unaveraged): -0.4670
Step: 740 Loss (unaveraged): -0.4682
Step: 750 Loss (unaveraged): -0.4332
Step: 760 Loss (unaveraged): -0.4333
Step: 770 Loss (unaveraged): -0.3674
Step: 780 Loss (unaveraged): -0.3178
Step: 790 Loss (unaveraged): -0.3160
Step: 800 Loss (unaveraged): -0.2502
Step: 810 Loss (unaveraged): -0.2445
Step: 820 Loss (unaveraged): -0.1748
Step: 830 Loss (unaveraged): -0.1175
Step: 840 Loss (unaveraged): -0.0583
Step: 850 Loss (unaveraged): -0.0403
Step: 860 Loss (unaveraged): -0.0346
Step: 870 Loss (unaveraged): 0.0240
Step: 880 Loss (unaveraged): 0.0381
Step: 890 Loss (unaveraged): -0.0018
Step: 900 Loss (unaveraged): -0.0359
Step: 910 Loss (unaveraged): -0.1063
Step: 920 Loss (unaveraged): -0.1582
Step: 930 Loss (unaveraged): -0.2420
Step: 940 Loss (unaveraged): -0.3664
Step: 950 Loss (unaveraged): -0.4980
Step: 960 Loss (unaveraged): -0.6276
Step: 970 Loss (unaveraged): -0.7700
Step: 980 Loss (unaveraged): -0.9080
Step: 990 Loss (unaveraged): -1.0263
Step: 1000 Loss (unaveraged): -1.1450
Step: 1010 Loss (unaveraged): -1.2609
Step: 1020 Loss (unaveraged): -1.3168
Step: 1030 Loss (unaveraged): -1.3711
Step: 1040 Loss (unaveraged): -1.3551
Step: 1050 Loss (unaveraged): -1.4068
Step: 1060 Loss (unaveraged): -1.3359
Step: 1070 Loss (unaveraged): -1.3419
Step: 1080 Loss (unaveraged): -1.2792
Step: 1090 Loss (unaveraged): -1.1643
Step: 1100 Loss (unaveraged): -1.1572
Step: 1110 Loss (unaveraged): -1.0610
Step: 1120 Loss (unaveraged): -0.9834
Step: 1130 Loss (unaveraged): -0.8939
Step: 1140 Loss (unaveraged): -0.8924
Step: 1150 Loss (unaveraged): -0.9234
Step: 1160 Loss (unaveraged): -0.9195
Step: 1170 Loss (unaveraged): -1.0154
Step: 1180 Loss (unaveraged): -1.0727
Step: 1190 Loss (unaveraged): -1.1837
Step: 1200 Loss (unaveraged): -1.3595
Step: 1210 Loss (unaveraged): -1.5077
Step: 1220 Loss (unaveraged): -1.7151
Step: 1230 Loss (unaveraged): -1.8459
Step: 1240 Loss (unaveraged): -2.0224
Step: 1250 Loss (unaveraged): -2.2277
Step: 1260 Loss (unaveraged): -2.3753
Step: 1270 Loss (unaveraged): -2.5096
Step: 1280 Loss (unaveraged): -2.6612
Step: 1290 Loss (unaveraged): -2.8014
Step: 1300 Loss (unaveraged): -3.0284
Step: 1310 Loss (unaveraged): -3.0857
Step: 1320 Loss (unaveraged): -3.1599
Step: 1330 Loss (unaveraged): -3.1137
Step: 1340 Loss (unaveraged): -3.0382
Step: 1350 Loss (unaveraged): -3.0079
Step: 1360 Loss (unaveraged): -2.9954
Step: 1370 Loss (unaveraged): -2.7851
Step: 1380 Loss (unaveraged): -2.6662
Step: 1390 Loss (unaveraged): -2.7068
Step: 1400 Loss (unaveraged): -2.6880
Step: 1410 Loss (unaveraged): -2.6318
Step: 1420 Loss (unaveraged): -2.6921
Step: 1430 Loss (unaveraged): -2.7741
Step: 1440 Loss (unaveraged): -2.8763
Step: 1450 Loss (unaveraged): -3.0547
Step: 1460 Loss (unaveraged): -3.1402
Step: 1470 Loss (unaveraged): -3.2379
Step: 1480 Loss (unaveraged): -3.3816
Step: 1490 Loss (unaveraged): -3.4608
Step: 1500 Loss (unaveraged): -3.4896
Step: 1510 Loss (unaveraged): -3.5004
Step: 1520 Loss (unaveraged): -3.4692
Step: 1530 Loss (unaveraged): -3.3542
Step: 1540 Loss (unaveraged): -3.3647
Step: 1550 Loss (unaveraged): -3.1929
Step: 1560 Loss (unaveraged): -3.0919
Step: 1570 Loss (unaveraged): -3.0181
Step: 1580 Loss (unaveraged): -2.8258
Step: 1590 Loss (unaveraged): -2.7320
Step: 1600 Loss (unaveraged): -2.5256
Step: 1610 Loss (unaveraged): -2.3158
Step: 1620 Loss (unaveraged): -2.2344
Step: 1630 Loss (unaveraged): -2.0130
Step: 1640 Loss (unaveraged): -1.6731
Step: 1650 Loss (unaveraged): -1.4628
Step: 1660 Loss (unaveraged): -1.1161
Step: 1670 Loss (unaveraged): -0.8540
Step: 1680 Loss (unaveraged): -0.5525
Step: 1690 Loss (unaveraged): -0.2562
Step: 1700 Loss (unaveraged): 0.0145
Step: 1710 Loss (unaveraged): 0.3249
Step: 1720 Loss (unaveraged): 0.5591
Step: 1730 Loss (unaveraged): 0.8105
Step: 1740 Loss (unaveraged): 0.9856
Step: 1750 Loss (unaveraged): 1.1553
Step: 1760 Loss (unaveraged): 1.3218
Step: 1770 Loss (unaveraged): 1.3759
Step: 1780 Loss (unaveraged): 1.4426
Step: 1790 Loss (unaveraged): 1.4799
Step: 1800 Loss (unaveraged): 1.4195
Step: 1810 Loss (unaveraged): 1.4576
Step: 1820 Loss (unaveraged): 1.4470
Step: 1830 Loss (unaveraged): 1.4258
Step: 1840 Loss (unaveraged): 1.3327
Step: 1850 Loss (unaveraged): 1.3229
Step: 1860 Loss (unaveraged): 1.2535
Step: 1870 Loss (unaveraged): 1.1721
Step: 1880 Loss (unaveraged): 1.0962
Step: 1890 Loss (unaveraged): 1.0264
Step: 1900 Loss (unaveraged): 0.9472
Step: 1910 Loss (unaveraged): 0.8718
Step: 1920 Loss (unaveraged): 0.7974
Step: 1930 Loss (unaveraged): 0.7120
Step: 1940 Loss (unaveraged): 0.6448
Step: 1950 Loss (unaveraged): 0.5548
Step: 1960 Loss (unaveraged): 0.4813
Step: 1970 Loss (unaveraged): 0.4050
Step: 1980 Loss (unaveraged): 0.3001
Step: 1990 Loss (unaveraged): 0.2331
Step: 2000 Loss (unaveraged): 0.1426
Step: 2010 Loss (unaveraged): 0.0604
Step: 2020 Loss (unaveraged): -0.0240
Step: 2030 Loss (unaveraged): -0.1044
Step: 2040 Loss (unaveraged): -0.1976
Step: 2050 Loss (unaveraged): -0.2779
Step: 2060 Loss (unaveraged): -0.3750
Step: 2070 Loss (unaveraged): -0.4599
Step: 2080 Loss (unaveraged): -0.5532
Step: 2090 Loss (unaveraged): -0.6541
Step: 2100 Loss (unaveraged): -0.7465
Step: 2110 Loss (unaveraged): -0.8328
Step: 2120 Loss (unaveraged): -0.9329
Step: 2130 Loss (unaveraged): -1.0550
Traceback (most recent call last):
  File "/Users/nicolafraccarolo/Documents/GitHub/torchsde/examples/sde_gan_original.py", line 485, in <module>
    fire.Fire(main)
  File "/Users/nicolafraccarolo/miniforge3/envs/ml-env/lib/python3.8/site-packages/fire/core.py", line 141, in Fire
    component_trace = _Fire(component, args, parsed_flag_args, context, name)
  File "/Users/nicolafraccarolo/miniforge3/envs/ml-env/lib/python3.8/site-packages/fire/core.py", line 475, in _Fire
    component, remaining_args = _CallAndUpdateTrace(
  File "/Users/nicolafraccarolo/miniforge3/envs/ml-env/lib/python3.8/site-packages/fire/core.py", line 691, in _CallAndUpdateTrace
    component = fn(*varargs, **kwargs)
  File "/Users/nicolafraccarolo/Documents/GitHub/torchsde/examples/sde_gan_original.py", line 437, in main
    loss.backward()
  File "/Users/nicolafraccarolo/miniforge3/envs/ml-env/lib/python3.8/site-packages/torch/_tensor.py", line 492, in backward
    torch.autograd.backward(
  File "/Users/nicolafraccarolo/miniforge3/envs/ml-env/lib/python3.8/site-packages/torch/autograd/__init__.py", line 251, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
  File "/Users/nicolafraccarolo/miniforge3/envs/ml-env/lib/python3.8/site-packages/torch/autograd/function.py", line 288, in apply
    return user_fn(self, *args)
  File "/Users/nicolafraccarolo/miniforge3/envs/ml-env/lib/python3.8/site-packages/torchsde/_core/adjoint.py", line 98, in backward
    (_, aug_state), *extra_solver_state = _SdeintAdjointMethod.apply(adjoint_sde,
  File "/Users/nicolafraccarolo/miniforge3/envs/ml-env/lib/python3.8/site-packages/torch/autograd/function.py", line 539, in apply
    return super().apply(*args, **kwargs)  # type: ignore[misc]
  File "/Users/nicolafraccarolo/miniforge3/envs/ml-env/lib/python3.8/site-packages/torchsde/_core/adjoint.py", line 52, in forward
    ys, extra_solver_state = solver.integrate(y0, ts, extra_solver_state)
  File "/Users/nicolafraccarolo/miniforge3/envs/ml-env/lib/python3.8/site-packages/torchsde/_core/base_solver.py", line 145, in integrate
    curr_y, curr_extra = self.step(curr_t, next_t, curr_y, curr_extra)
  File "/Users/nicolafraccarolo/miniforge3/envs/ml-env/lib/python3.8/site-packages/torchsde/_core/methods/reversible_heun.py", line 124, in step
    vjp_z, *vjp_params = misc.vjp(outputs=(re_forward_f0, re_forward_g0),
  File "/Users/nicolafraccarolo/miniforge3/envs/ml-env/lib/python3.8/site-packages/torchsde/_core/misc.py", line 80, in vjp
    _vjp = torch.autograd.grad(outputs, inputs, **kwargs)
  File "/Users/nicolafraccarolo/miniforge3/envs/ml-env/lib/python3.8/site-packages/torch/autograd/__init__.py", line 394, in grad
    result = Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt